<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.4.2',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="学习在阿里云上搭建 Hadoop + HBase + Hive + Spark 集群的笔记。搭建过程中遇到了很多问题，在查阅资料的过程中也走了很多弯路。在这里将搭建步骤和问题一一记录，既方便日后复习，也为其它小伙伴提供一些帮助。 本篇是笔记的第一部分，从准备工作开始，到 Hadoop 集群搭建完成为止。">
<meta name="keywords" content="大数据,Hadoop">
<meta property="og:type" content="article">
<meta property="og:title" content="阿里云配置 Hadoop + HBase + Hive + Spark 集群（一）">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;11&#x2F;24&#x2F;%E9%98%BF%E9%87%8C%E4%BA%91Spark-1&#x2F;index.html">
<meta property="og:site_name" content="陈逸凡的博客">
<meta property="og:description" content="学习在阿里云上搭建 Hadoop + HBase + Hive + Spark 集群的笔记。搭建过程中遇到了很多问题，在查阅资料的过程中也走了很多弯路。在这里将搭建步骤和问题一一记录，既方便日后复习，也为其它小伙伴提供一些帮助。 本篇是笔记的第一部分，从准备工作开始，到 Hadoop 集群搭建完成为止。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;11&#x2F;24&#x2F;%E9%98%BF%E9%87%8C%E4%BA%91Spark-1&#x2F;HadoopVersion.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;11&#x2F;24&#x2F;%E9%98%BF%E9%87%8C%E4%BA%91Spark-1&#x2F;DataNodeInfo.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;11&#x2F;24&#x2F;%E9%98%BF%E9%87%8C%E4%BA%91Spark-1&#x2F;PI.png">
<meta property="og:updated_time" content="2020-02-10T01:54:06.768Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;11&#x2F;24&#x2F;%E9%98%BF%E9%87%8C%E4%BA%91Spark-1&#x2F;HadoopVersion.png">

<link rel="canonical" href="http://yoursite.com/2019/11/24/%E9%98%BF%E9%87%8C%E4%BA%91Spark-1/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>阿里云配置 Hadoop + HBase + Hive + Spark 集群（一） | 陈逸凡的博客</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?57b343bca810fd9bc6bbf4ed8bd15279";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">陈逸凡的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">我想玩丝之歌</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/24/%E9%98%BF%E9%87%8C%E4%BA%91Spark-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="陈逸凡">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="陈逸凡的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          阿里云配置 Hadoop + HBase + Hive + Spark 集群（一）
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-11-24 13:49:48" itemprop="dateCreated datePublished" datetime="2019-11-24T13:49:48-05:00">2019-11-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-02-09 20:54:06" itemprop="dateModified" datetime="2020-02-09T20:54:06-05:00">2020-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">笔记</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>学习在阿里云上搭建 Hadoop + HBase + Hive + Spark 集群的笔记。搭建过程中遇到了很多问题，在查阅资料的过程中也走了很多弯路。在这里将搭建步骤和问题一一记录，既方便日后复习，也为其它小伙伴提供一些帮助。</p>
<p>本篇是笔记的第一部分，从准备工作开始，到 Hadoop 集群搭建完成为止。</p>
<a id="more"></a>

<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><h2 id="购买阿里云服务器"><a href="#购买阿里云服务器" class="headerlink" title="购买阿里云服务器"></a>购买阿里云服务器</h2><p>在阿里云上配置集群，要做的第一件事情自然是购买阿里云服务器。阿里云上产品种类繁多，初学者（比如我）很容易看花了眼。不过很快我就在新手套餐里找到了合适的服务器。我使用了三台单核 1G 内存的服务器，预装 CentOS 7，并计划以其中一台作为 master 节点，另两台作为 slave 节点搭建我的 hadoop 集群。购买服务器时要注意你所在的位置。我在美国东部留学，选择了弗吉尼亚节点。三台机器（包括免费试用的一台）一个月总共 11 美元，并不昂贵。</p>
<p>购买服务器的过程中会提示你新建密码或者新建密钥对。如果你不清楚这些是什么，可以暂时跳过，因为这些都可以在稍后进行设置。</p>
<p>购买完成后可以先在控制台修改实例名称为 master/slave01/slave02，这样后面就不需要再修改主机名了。</p>
<blockquote>
<p>在后来的实践中发现服务器性能太弱，几乎不能完成任何有实际价值的任务。所以后来升级到了三台双核 4G 服务器，加了 45 美元</p>
</blockquote>
<br />

<h2 id="ssh-免密码登录"><a href="#ssh-免密码登录" class="headerlink" title="ssh 免密码登录"></a>ssh 免密码登录</h2><blockquote>
<p>参考资料：<a href="https://help.aliyun.com/document_detail/51798.html" target="_blank" rel="noopener">https://help.aliyun.com/document_detail/51798.html</a></p>
</blockquote>
<h3 id="本地到服务器"><a href="#本地到服务器" class="headerlink" title="本地到服务器"></a>本地到服务器</h3><p>我们可以从本地连接到服务器进行远程管理。为了避免繁琐的密码输入，我们需要对 ssh 进行一些配置。</p>
<blockquote>
<p>即使你打算使用密码进行远程连接，我也建议你耐心地看完这一段。因为本段中涉及到的方法，在后文服务器之间的免密互联中会再次用到</p>
</blockquote>
<p>首先要为服务器绑定 ssh 密钥对。在云服务器管理控制台页面左侧菜单中有<code>网络与安全 -&gt; 密钥对</code>子页面，你可以在这里新建并绑定密钥对。当然，你也可以选择在购买服务器的过程中新建并绑定密钥对。包括密钥对绑定在内的很多设定都是可以自由修改的，所以你可以随意选择使用何种方式。安全起见，这一步可以将登陆密码一并进行设置或修改（同样是在实例页面中）。这里你会遇到两种密码，分别是实例密码和远程连接密码。前者是这台实例上 root 用户的密码，而后者是在阿里云提供的网页上，远程连接管理实例时使用的密码，需要稍作区分。</p>
<blockquote>
<p>新建密钥对后有且仅有一次机会下载私钥，要注意及时妥善地下载保存</p>
</blockquote>
<p>接下来我们需要在本地进行一些操作。我是在 Mac 环境下进行开发，接下来所有的描述都以 Mac 环境作为背景。如果你是 Windows 用户，可以参考<a href="https://help.aliyun.com/document_detail/51798.html" target="_blank" rel="noopener">阿里云的官方文档</a>。</p>
<p>官方文档中提供了两种连接方式。第一种通过<code>ssh -i</code>命令访问服务器，第二种则通过修改 ssh 配置信息进行访问。在开始配置前，请确保 .pem 私钥文件已被妥善下载到本地，并被保存至合适的的路径。</p>
<p><strong>第一种方法：</strong></p>
<p>首先通过<code>chmod</code>命令修改 .pem 私钥文件的权限。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 400 [.pem 文件路径]</span><br></pre></td></tr></table></figure>

<p>上面的命令将私钥文件设定为只对文件拥有者可读，可以避免私钥被意外修改。接下来在终端中输入下方命令就可以远程访问我们的服务器了。实例的公网 IP 地址可以很轻松地在实例页面中查到。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -i [.pem 文件路径] root@[实例公网 IP 地址]</span><br></pre></td></tr></table></figure>

<blockquote>
<p>第一种方法并不方便，但是我们有办法利用它。如果你的终端能够记忆历史命令，那么只要输入<code>ssh -i</code>再按方向键就可以了。如果没有安装这样的功能，也可以修改终端配置文件，为上面的命令设置一个别名</p>
</blockquote>
<p><strong>第二种方法：</strong></p>
<p>使用<code>vi</code>打开<code>/etc/ssh</code>文件夹下的<code>ssh_config</code>文件。这个文件记录了 ssh 客户端的各种配置。将下面的代码添加到<code>ssh_config</code>文件的末尾：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Host master  # 实例的名字，由你自行定义，建议使用 master, slave01, slave02 方便记忆</span><br><span class="line">    HostName 192.*.*.*  # 实例的公网 IP 地址</span><br><span class="line">    Port 22  # 端口号，默认为 22</span><br><span class="line">    User root  # 登录账号</span><br><span class="line">    IdentityFile /root/...  # 私钥的地址</span><br></pre></td></tr></table></figure>

<p><code>ssh_config</code>文件中的配置是以<code>Host</code>作为标记区分段落的。你可以根据需要添加多个不同的以<code>Host</code>为开头的段落，来为不同的服务器进行配置。保存文件并重启 ssh 后，通过下面的命令就可以连接到实例了：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh ecs  // ecs 是上面配置中实例的名称，注意对应</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Mac 对于<code>ssh_config</code>文件有权限保护。我暂时还没研究绕开权限的方法，留待以后补充</p>
</blockquote>
<br />

<h3 id="服务器到服务器"><a href="#服务器到服务器" class="headerlink" title="服务器到服务器"></a>服务器到服务器</h3><p>上面的步骤完成后，我们就可以方便地从本地连接到 master 节点进行管理了。但是仅仅这样是完全不够的。在分布式计算的过程中，我们的服务器间会产生大量的数据通信。如果每次通信都要输入密码，那将会是非常可怕的事情。为此我们还要配置服务器之间的 ssh 免密。</p>
<p>连接到 master 服务器，创建一个新目录用于存放各种软件。我创建的目录是<code>/root/software</code>，而你可以选择其它喜爱的目录。回到本地，执行下面的命令，将 .pem 文件上传到 master 服务器：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp [.pem 文件地址] root@[实例的公网 IP]:/root/software/  // 注意对应到你自己的目录</span><br></pre></td></tr></table></figure>

<p>连接到服务器，参考本地连接服务器方法二对<code>ssh_config</code>进行修改。在这里你需要将全部三台服务器的信息加入<code>ssh_config</code>文件中（即输入三段以<code>Host</code>为开头的配置）。一切完成后，输入<code>service sshd restart</code>命令重启 ssh 服务。接着使用下面的命令测试连接：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh master  // 你配置的 Host 名称，将三个服务器的名称都试验一遍吧！</span><br></pre></td></tr></table></figure>

<p>第一次连接可能会有提示信息，根据提示输入<code>yes</code>即可。至此你应该已经完成了一台服务器的免密设置了。再接再厉，完成其它两台服务器的配置吧！</p>
<blockquote>
<p>我在网上找到的其它资料都是在服务器上新生成一个密钥对，然后分配到其它服务器中。但是既然阿里云已经为我们绑定了密钥对，何不直接利用它呢？上面的方法经过我个人测试是有效的</p>
</blockquote>
<br />

<h2 id="配置-hosts-文件"><a href="#配置-hosts-文件" class="headerlink" title="配置 hosts 文件"></a>配置 hosts 文件</h2><p>在每一个节点上打开<code>/etc/hosts</code>，将三台节点的内网 IP 信息添加到末尾：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">172.**.***.*** master master</span><br><span class="line">172.**.***.*** slave01 slave01</span><br><span class="line">172.**.***.*** slave02 slave02</span><br></pre></td></tr></table></figure>

<br />

<h2 id="安装配置-Java-SDK"><a href="#安装配置-Java-SDK" class="headerlink" title="安装配置 Java SDK"></a>安装配置 Java SDK</h2><blockquote>
<p>参考资料：<a href="https://yq.aliyun.com/articles/47236" target="_blank" rel="noopener">https://yq.aliyun.com/articles/47236</a></p>
</blockquote>
<p>首先我们需要将 JDK 下载到服务器上。实现的办法有很多，这里我采用的是先下载到本地，再上传到服务器的方法。到<a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">Orcale 网站</a>下载 Linux x64 版本 JDK 到本地。接着输入下方的命令就可以把本地的 JDK 上传到服务器上了：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp [本地 JDK 地址] root@[实例的公网 IP]:/root/software/  // 注意将要存放 JDK 的目录修改为你的目录</span><br></pre></td></tr></table></figure>

<p>这一步可能需要输入 root 用户的密码。提交命令，稍安勿躁，很快你就能在服务器上看到 JDK 了。</p>
<blockquote>
<p>如果你已经完成了免密通信的配置，那么这里的公网 IP 可以替换成对应的 Host 名称</p>
</blockquote>
<p>接着新建一个目录作为 JDK 的安装路径：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /usr/java</span><br></pre></td></tr></table></figure>

<p>回到 software 目录，执行下方命令解压缩包：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf jdk-8u231-linux-x64.tar.gz  // 文件名应该以你下载的为准</span><br></pre></td></tr></table></figure>

<p>现在执行<code>ls</code>命令，可以发现 software 目录下多出了一个 jdk 开头的文件夹。用下面的命令将这个文件夹移动到刚才创建的<code>/usr/java/</code>目录中:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv jdk1.8.0_231/ /usr/java</span><br></pre></td></tr></table></figure>

<p>接下来配置环境变量。使用<code>vi /root/.bash_profile</code>打开配置文件，将下方的代码加入文件最后：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_231  # 注意替换成你自己的 jdk 文件夹</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br></pre></td></tr></table></figure>

<p>保存退出。别忘记执行<code>source ~/.bash_profile</code>重新加载配置文件。这一切完成后就可以执行下面的代码来检验成果了：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure>

<p>如果你的终端中出现了 java 版本信息，那么祝贺你，安装成功了！不过，现在就放松精神还为时过早。你还需要为其它两台服务器安装 java。收拾耐心，一鼓作气地将工作全部完成吧！</p>
<p>至此基本的准备工作已经完成了，我们可以开始搭建我们的集群了！</p>
<br />

<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h2 id="安装-Hadoop"><a href="#安装-Hadoop" class="headerlink" title="安装 Hadoop"></a>安装 Hadoop</h2><p>首先到<a href="https://hadoop.apache.org/releases.html" target="_blank" rel="noopener">Hadoop 官网</a>下载安装包，并上传到 master 节点。我选择的是 3.1.3 版本：</p>
<blockquote>
<p>最初我选择的是 2.10.0 版本，但这个版本似乎和 hbase 2.2.2 版本有冲突，因此后来重装了 3.1.3 版本</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp [本地安装包路径] root@[master 节点公网 IP]:/usr/local</span><br></pre></td></tr></table></figure>

<p>解压，顺便重新赋予一个便于输入的名字：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hadoop-3.1.3</span><br><span class="line">mv hadoop-3.1.3 hadoop</span><br></pre></td></tr></table></figure>

<p>现在适合配置环境变量！打开<code>/root/.bash_profile</code>，在末尾添加如下内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/usr/local/hadoop</span><br><span class="line">export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin</span><br></pre></td></tr></table></figure>

<p>别忘记执行<code>source /root/.bash_profile</code>重新加载配置文件。现在可以执行下面的命令来检查 Hadoop 是否成功安装。成功安装的话就会出现 Hadoop 版本信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop version</span><br></pre></td></tr></table></figure>

<p><img src="HadoopVersion.png" alt=""></p>
<p>上面的步骤暂时只需要在 master 节点执行就可以了。slave 节点上的配置，可以等到 master 节点配置完成后再进行不迟。</p>
<br />

<h2 id="Hadoop-集群配置和启动"><a href="#Hadoop-集群配置和启动" class="headerlink" title="Hadoop 集群配置和启动"></a>Hadoop 集群配置和启动</h2><p>详细的配置说明请参考<a href="https://hadoop.apache.org/docs/r3.1.3/hadoop-project-dist/hadoop-common/ClusterSetup.html" target="_blank" rel="noopener">Hadoop 官方文档</a>。Hadoop 配置文件目录为<code>/usr/local/hadoop/etc/hadoop</code>（注意区分你自己的安装目录）。我们首先进入配置文件目录。</p>
<br />

<h3 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h3><p>打开<code>core-site.xml</code>，将 configuration 标签下的内容进行如下修改：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>A base for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<br />

<h3 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h3><p>打开<code>hdfs-site.xml</code>，将 configuration 标签下的内容进行如下修改：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<br />

<h3 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h3><p>倘若你使用的是 Hadoop 2，首先先通过下面的命令重命名文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv mapred-site.xml.template mapred-site.xml</span><br></pre></td></tr></table></figure>

<p>打开，进行如下修改：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/usr/local/hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/usr/local/hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/usr/local/hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<br />

<h3 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h3><p>打开<code>yarn-site.xml</code>进行如下修改：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10240<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>5<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<br />

<h3 id="hadoop-env-sh"><a href="#hadoop-env-sh" class="headerlink" title="hadoop-env.sh"></a>hadoop-env.sh</h3><p>打开<code>hadoop-env.sh</code>，在文件开始处添加以下内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_231</span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop</span><br><span class="line">export PATH=$PATH:/usr/local/hadoop/bin</span><br><span class="line"></span><br><span class="line">export HDFS_NAMENODE_USER="root"</span><br><span class="line">export HDFS_DATANODE_USER="root"</span><br><span class="line">export HDFS_SECONDARYNAMENODE_USER="root"</span><br><span class="line">export YARN_RESOURCEMANAGER_USER="root"</span><br><span class="line">export YARN_NODEMANAGER_USER="root"</span><br></pre></td></tr></table></figure>

<br />

<h3 id="配置-slaves"><a href="#配置-slaves" class="headerlink" title="配置 slaves"></a>配置 slaves</h3><p>打开<code>workers</code>，删掉默认的 localhost，添加：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slave01</span><br><span class="line">slave02</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Hadoop 2 中对应的文件名是 slaves</p>
</blockquote>
<br />

<h3 id="复制-hadoop-文件夹到各个节点"><a href="#复制-hadoop-文件夹到各个节点" class="headerlink" title="复制 hadoop 文件夹到各个节点"></a>复制 hadoop 文件夹到各个节点</h3><p>现在直接将 master 节点上的 hadoop 文件夹复制到各个节点，就可以省下安装和配置的步骤：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /usr/local/hadoop slave01:/usr/local</span><br><span class="line">scp -r /usr/local/hadoop slave02:/usr/local</span><br></pre></td></tr></table></figure>

<br />

<h3 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h3><p>首先在 master 节点上启动 hadoop。执行以下命令格式化各节点信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs datanode -format</span><br><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>

<p>接着启动 hadoop 环境：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/hadoop/sbin/start-dfs.sh</span><br><span class="line">/usr/local/hadoop/sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>

<blockquote>
<p>遇到问题不要慌，仔细看 ERROR 信息和日志，百度一下，你就知道</p>
</blockquote>
<br />

<h2 id="Hadoop-集群检查"><a href="#Hadoop-集群检查" class="headerlink" title="Hadoop 集群检查"></a>Hadoop 集群检查</h2><blockquote>
<p>参考资料：<a href="http://xuxping.com/2017/04/04/Hadoop集群检查/" target="_blank" rel="noopener">Kavim 的博文</a></p>
</blockquote>
<p>接下来项目中几乎所有内容都倚赖于 Hadoop，因此在这一步进行充分的检查是合理而有必要的。</p>
<br />

<h3 id="集群启动"><a href="#集群启动" class="headerlink" title="集群启动"></a>集群启动</h3><p>首先检查集群是否正常启动。</p>
<h4 id="查看进程"><a href="#查看进程" class="headerlink" title="查看进程"></a>查看进程</h4><p>启动 Hadoop 后，运行 jps 命令，查看当前的 java 进程：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br></pre></td></tr></table></figure>

<p>如果能在 master 节点看到 NameNode，SecondaryNameNode 和 ResourceManager 的进程，并在 slave 节点看到 DataNode 和 NodeManager 进程，则说明启动成功。</p>
<blockquote>
<p>也可以使用<code>hadoop dfsadmin -report</code>命令查看详细的运行状态</p>
</blockquote>
<h4 id="Web-界面"><a href="#Web-界面" class="headerlink" title="Web 界面"></a>Web 界面</h4><p>Hadoop 提供了非常便利的 Web 界面方便我们监控集群运作的状态。不同组件 Web 界面对应的端口号如下：</p>
<table>
<thead>
<tr>
<th>Daemon</th>
<th>Port</th>
</tr>
</thead>
<tbody><tr>
<td>NameNode</td>
<td>9870</td>
</tr>
<tr>
<td>ResourceManager</td>
<td>8088</td>
</tr>
<tr>
<td>MapReduce JobHistory Server</td>
<td>19888</td>
</tr>
</tbody></table>
<p>可以在本地的浏览器内，通过访问<code>http://master 节点的 IP 地址:port</code>查看对应组件的状态。需要注意的是，访问 Web 界面需要阿里云开放对应的端口，如果没有开放，则需要在阿里云控制台的安全组设置内进行设置。</p>
<p><img src="DataNodeInfo.png" alt=""></p>
<blockquote>
<p>这张截图是 Hadoop 2 下的，和 Hadoop 3 大同小异</p>
</blockquote>
<p>Hadoop 2 中，NameNode 默认端口为 50070，而实际应用中开放 50070 端口会带来严重的安全问题。详情请参考：<a href="https://yq.aliyun.com/articles/68945?spm=a2c6h.13066369.0.0.6f4e16809oQWIG" target="_blank" rel="noopener">Hadoop 黑客赎金事件解读及防范</a></p>
<br />

<h3 id="集群运行"><a href="#集群运行" class="headerlink" title="集群运行"></a>集群运行</h3><p>接着我们通过一些实际任务检查集群是否正常运行。最好的检查办法莫过于实际运行任务。这里测试一下 Hadoop 自带的 pi 任务。进入<code>/usr/lcoal/hadoop/bin</code>，执行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar pi 10 10</span><br></pre></td></tr></table></figure>

<p>似乎由于内存比较小，经历了数次失败才最终成功。如果你的服务器和我的一样羸弱，不妨尝试小一点的参数。测试结果如下：</p>
<p><img src="PI.png" alt=""></p>
<br />

<h2 id="安装配置过程中遇到的问题"><a href="#安装配置过程中遇到的问题" class="headerlink" title="安装配置过程中遇到的问题"></a>安装配置过程中遇到的问题</h2><p>每个人使用的系统环境和安装版本都有所区别，直接照搬网络上的资料可能会遇到各种问题。在这里是我个人安装过程中遇到的一些问题以及解决的方法。解决方案已经融合进了前文的安装配置之中，在此单独列出，以便日后查阅。</p>
<p><strong>1. 无法连接到 Web 界面</strong></p>
<p>原因是阿里云没有开放对应端口。到阿里云控制台内开放端口即可。不排除某些情况下是由于 Hadoop 集群没有正常启动，使用时要注意筛查。</p>
<p><strong>2. Hadoop 集群启动，但是 master 和 slaves 之间的通信不正常</strong></p>
<p>原因是没有配置 host 文件。将内网 IP 信息正确配置后问题解决。</p>
<p><strong>3. 提示<code>HDFS_NAMENODE_USER</code>不为<code>root</code></strong></p>
<p>在配置文件中将其设置为<code>root</code>即可。出现这个问题后根据网络资料顺便设置了其它几个变量。这个问题在 Hadoop 2 中没有遇到。</p>
<p><strong>4. master 节点进程正常，slave 节点没有 DataNode</strong><br>重启之前删除各个节点的 logs 和 tmp 文件夹，然后再 format。不过我不清楚这个方法究竟是解决了问题，还是误打误撞。</p>
<p><strong>5. 运行 pi 测试程序失败，提示虚拟内存不足</strong><br>在<code>yarn-site.xml</code>中加入如下配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>5<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>Hadoop 中虚拟内存的大小是实际内存的一定倍数，其默认值为 2.1 倍。这里我们将它增加到 5 倍就可以解决问题。</p>
<p><strong>6. 运行 pi 测试程序失败，reducer 拉取数据失败</strong><br>错误信息：<code>Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#4</code>。问题的原因是 fetcher 拉取并保存到内存中的数据过大，导致内存溢出。具体解决方案可以参考<a href="https://blog.csdn.net/smile0198/article/details/44133379" target="_blank" rel="noopener">安金龙的博文</a>。我的测试在经历了数次重试后完成了任务，所以我并没有进行相应的修改。</p>
<p><strong>7. 运行 pi 测试失败，需要设置<code>HADOOP_MAPRED_HOME</code></strong><br>Typora 崩溃丢失数据了，导致我现在也不清楚当时错误提示信息具体是什么。不过还记得解决方案以及，在查阅资料后得知，Hadoop 3 中不同 service 变量不继承。于是即便<code>HADOOP_HOME</code>和<code>HADOOP_MAPRED_HOME</code>两者相等，还是要分别进行配置。在<code>mapred-site.xml</code>中增加下面的配置即可：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/usr/local/hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/usr/local/hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/usr/local/hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"># 大数据</a>
              <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2019/10/30/%E6%88%91%E7%9A%84%E7%8B%97%E5%95%8A/" rel="next" title="我的狗啊">
                  <i class="fa fa-chevron-left"></i> 我的狗啊
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/2019/11/30/%E9%98%BF%E9%87%8C%E4%BA%91Spark-2/" rel="prev" title="阿里云配置 Hadoop + HBase + Hive + Spark 集群（二）">
                  阿里云配置 Hadoop + HBase + Hive + Spark 集群（二） <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    
  <div class="comments" id="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC80NzgzOC8yNDMzNQ=="></div>
  </div>
  

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#准备工作"><span class="nav-number">1.</span> <span class="nav-text">准备工作</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#购买阿里云服务器"><span class="nav-number">1.1.</span> <span class="nav-text">购买阿里云服务器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ssh-免密码登录"><span class="nav-number">1.2.</span> <span class="nav-text">ssh 免密码登录</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#本地到服务器"><span class="nav-number">1.2.1.</span> <span class="nav-text">本地到服务器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#服务器到服务器"><span class="nav-number">1.2.2.</span> <span class="nav-text">服务器到服务器</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#配置-hosts-文件"><span class="nav-number">1.3.</span> <span class="nav-text">配置 hosts 文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#安装配置-Java-SDK"><span class="nav-number">1.4.</span> <span class="nav-text">安装配置 Java SDK</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hadoop"><span class="nav-number">2.</span> <span class="nav-text">Hadoop</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#安装-Hadoop"><span class="nav-number">2.1.</span> <span class="nav-text">安装 Hadoop</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop-集群配置和启动"><span class="nav-number">2.2.</span> <span class="nav-text">Hadoop 集群配置和启动</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#core-site-xml"><span class="nav-number">2.2.1.</span> <span class="nav-text">core-site.xml</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hdfs-site-xml"><span class="nav-number">2.2.2.</span> <span class="nav-text">hdfs-site.xml</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mapred-site-xml"><span class="nav-number">2.2.3.</span> <span class="nav-text">mapred-site.xml</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#yarn-site-xml"><span class="nav-number">2.2.4.</span> <span class="nav-text">yarn-site.xml</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hadoop-env-sh"><span class="nav-number">2.2.5.</span> <span class="nav-text">hadoop-env.sh</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#配置-slaves"><span class="nav-number">2.2.6.</span> <span class="nav-text">配置 slaves</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#复制-hadoop-文件夹到各个节点"><span class="nav-number">2.2.7.</span> <span class="nav-text">复制 hadoop 文件夹到各个节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动集群"><span class="nav-number">2.2.8.</span> <span class="nav-text">启动集群</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop-集群检查"><span class="nav-number">2.3.</span> <span class="nav-text">Hadoop 集群检查</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#集群启动"><span class="nav-number">2.3.1.</span> <span class="nav-text">集群启动</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#查看进程"><span class="nav-number">2.3.1.1.</span> <span class="nav-text">查看进程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Web-界面"><span class="nav-number">2.3.1.2.</span> <span class="nav-text">Web 界面</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#集群运行"><span class="nav-number">2.3.2.</span> <span class="nav-text">集群运行</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#安装配置过程中遇到的问题"><span class="nav-number">2.4.</span> <span class="nav-text">安装配置过程中遇到的问题</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="陈逸凡"
    src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">陈逸凡</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">9</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">陈逸凡</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.4.2
  </div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  
















  

  

<script>
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
</script>

</body>
</html>
